[
  {
    "objectID": "HW 8 - Basic Modeling Practice.html",
    "href": "HW 8 - Basic Modeling Practice.html",
    "title": "ST558 - HW 8: Basic Modeling Practice",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(corrplot)\nlibrary(tidymodels)"
  },
  {
    "objectID": "HW 8 - Basic Modeling Practice.html#basic-modeling-practice",
    "href": "HW 8 - Basic Modeling Practice.html#basic-modeling-practice",
    "title": "ST558 - HW 8: Basic Modeling Practice",
    "section": "Basic Modeling Practice",
    "text": "Basic Modeling Practice\n\nReading Data\nToday we will do some structured practice with fitting linear models in R. The data set we will be using is about bike sharing rentals in Seoul, South Korea. Let’s begin by reading in this data.\n\nbike_data &lt;- read_csv(\"SeoulBikeData.csv\", locale = locale(encoding=\"latin1\")) # Locale solves problems with special characters in other languages.\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nEDA\n\nData Processing\nBefore we go fitting any models, we will conduct some basic data cleaning to prepare our data for usage. First, we will check for missing values and verify data types to make sure the columns were read in correctly.\n\n# Check structure of data\nstr(bike_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n# Check for missing values\ncolSums(is.na(bike_data)) \n\n                     Date         Rented Bike Count                      Hour \n                        0                         0                         0 \n          Temperature(°C)               Humidity(%)          Wind speed (m/s) \n                        0                         0                         0 \n         Visibility (10m) Dew point temperature(°C)   Solar Radiation (MJ/m2) \n                        0                         0                         0 \n             Rainfall(mm)             Snowfall (cm)                   Seasons \n                        0                         0                         0 \n                  Holiday           Functioning Day \n                        0                         0 \n\n\nWe can see that none of the columns have missing values! However, we should note that the Date column has been read in as a character type, so we will need to process this column further. The categorical variables Seasons, Holiday, and Functioning Day have also been read in as character type, so we will convert them to factor type for later analysis. The Date column is currently stored as a character string with the format day/month/year. We will convert it into a usable date object using the lubridate library.\n\nbike_data &lt;- bike_data |&gt;\n  mutate(Date = dmy(Date))\n\nNext, we will make sure that the categorical variables are read as factors.\n\nbike_data &lt;- bike_data |&gt;\n  mutate(Seasons = as.factor(Seasons),\n         Holiday = as.factor(Holiday),\n         `Functioning Day` = as.factor(`Functioning Day`))\n\nhead(bike_data)\n\n# A tibble: 6 × 14\n  Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n  &lt;date&gt;                   &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1 2017-12-01                 254     0              -5.2            37\n2 2017-12-01                 204     1              -5.5            38\n3 2017-12-01                 173     2              -6              39\n4 2017-12-01                 107     3              -6.2            40\n5 2017-12-01                  78     4              -6              36\n6 2017-12-01                 100     5              -6.4            37\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;fct&gt;, Holiday &lt;fct&gt;,\n#   `Functioning Day` &lt;fct&gt;\n\n\nFinally, we will rename all the variables to have more “user-friendly” names. For example, a column name like “Functioning Day” is not currently user-friendly because of the space between the words.\n\nbike_data &lt;- bike_data |&gt;\n  clean_names() # Replaces all spaces with '_' and makes all letters lowercase.\n\nnames(bike_data)\n\n [1] \"date\"                    \"rented_bike_count\"      \n [3] \"hour\"                    \"temperature_c\"          \n [5] \"humidity_percent\"        \"wind_speed_m_s\"         \n [7] \"visibility_10m\"          \"dew_point_temperature_c\"\n [9] \"solar_radiation_mj_m2\"   \"rainfall_mm\"            \n[11] \"snowfall_cm\"             \"seasons\"                \n[13] \"holiday\"                 \"functioning_day\"        \n\n\n\n\nExploratory Data Analysis\nNow that the bike data has been cleaned up, we can begin some basic exploratory data analysis (EDA). Let’s start by creating some summary statistics as they relate to the bike rental count. We will view these statistics across some categorical variables as well.\n\n# Summary of rented_bike_count variable.\nsummary(bike_data$rented_bike_count)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   191.0   504.5   704.6  1065.2  3556.0 \n\n# Find unique values for each categorical variable\nunique(bike_data$seasons)\n\n[1] Winter Spring Summer Autumn\nLevels: Autumn Spring Summer Winter\n\nunique(bike_data$holiday)\n\n[1] No Holiday Holiday   \nLevels: Holiday No Holiday\n\nunique(bike_data$functioning_day)\n\n[1] Yes No \nLevels: No Yes\n\n\nSince the functioning_day variable only has Yes or No values, this means that the bike sharing system was either operable or inoperable that hour. If the system was inoperable, then we get no useful information about bike rentals for that hour. In this case, we will remove observations that show the system was not operating.\n\ntable(bike_data$functioning_day) # 295 \"No \" observations\n\n\n  No  Yes \n 295 8465 \n\nbike_data &lt;- bike_data |&gt;\n  filter(functioning_day == \"Yes\")\n\nThe data is currently given as hourly observations. We will summarize across the hours so that each day has one observation associated with it. We will also group the data by date, seasons, and holiday. We will find the sum of the rented_bike_count, rainfall, and snowfall variables. Finally, we will included the mean of all the weather related variables.\n\ndaily_bike_data &lt;- bike_data %&gt;%\n  group_by(date, seasons, holiday) %&gt;%\n  summarise(\n    total_bike_count = sum(rented_bike_count),\n    avg_temp_c = mean(temperature_c, na.rm = TRUE),\n    avg_humidity_pct = mean(humidity_percent, na.rm = TRUE),\n    avg_windspeed_m_s = mean(wind_speed_m_s, na.rm = TRUE),\n    avg_visibility_10m = mean(visibility_10m, na.rm = TRUE),\n    avg_dew_point_temp_c = mean(dew_point_temperature_c, na.rm = TRUE),\n    avg_solar_radiation_mj_m2 = mean(solar_radiation_mj_m2, na.rm = TRUE),\n    total_rainfall_mm = sum(rainfall_mm, na.rm = TRUE),\n    total_snowfall_cm = sum(snowfall_cm, na.rm = TRUE)\n  )\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\nhead(daily_bike_data)\n\n# A tibble: 6 × 12\n# Groups:   date, seasons [6]\n  date       seasons holiday    total_bike_count avg_temp_c avg_humidity_pct\n  &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;                 &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;\n1 2017-12-01 Winter  No Holiday             9539    -2.45               45.9\n2 2017-12-02 Winter  No Holiday             8523     1.32               62.0\n3 2017-12-03 Winter  No Holiday             7222     4.88               81.5\n4 2017-12-04 Winter  No Holiday             8729    -0.304              52.5\n5 2017-12-05 Winter  No Holiday             8307    -4.46               36.4\n6 2017-12-06 Winter  No Holiday             6669     0.0458             70.8\n# ℹ 6 more variables: avg_windspeed_m_s &lt;dbl&gt;, avg_visibility_10m &lt;dbl&gt;,\n#   avg_dew_point_temp_c &lt;dbl&gt;, avg_solar_radiation_mj_m2 &lt;dbl&gt;,\n#   total_rainfall_mm &lt;dbl&gt;, total_snowfall_cm &lt;dbl&gt;\n\n\nNow, we have a daily_bike_data tibble, which will be our new data that we will analyze! Let’s recreate our basic summary statistics and then create some plots to explore variable relationships. We can also view a correlation matrix between our numeric variables to see if the data shows any significant correlations.\n\n# Summary of total_bike_count variable on a given day of the year.\nsummary(daily_bike_data$total_bike_count)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    977    6967   18563   17485   26285   36149 \n\n\n\nnum_vars &lt;- daily_bike_data[ , 4:12]\n\ncorrplot(cor(num_vars))\n\n\n\n\n\n\n\n\nBy looking at the correlation plot above, we can see that the total bike rental count has a strong, positive correlation with the average temperature and solar radiation. This makes sense because we can easily imagine more bikes being rented on a warm, sunny day rather than a cold, cloudy day.\n\n\nSplit the Data\nNow, we will move on to splitting our daily_bike_data into training and testing sets (75/25 split).\n\nset.seed(75)\n\nbike_split &lt;- initial_split(daily_bike_data, prop = 0.75, strata = seasons)\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\n\nWe will also create a 10 fold cross-validation (CV) split on the training set.\n\nbike_folds &lt;- vfold_cv(bike_train, v = 10)\n\n\n\nFitting MLR Models\nOur bike data is now ready for fitting linear regression models! First, let’s create some recipes.\nFor the 1st recipe, let’s ignore the date variable for modeling and instead use it to create a weekday/weekend (factor) variable.\n\nbike_recipe_1 &lt;- recipe(total_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt; # Give 'date' an ID to keep it, but not for modeling.\n  step_date(date, features = \"dow\", label = TRUE) |&gt; # Pull out week days from date.\n  \n  # Create new weekday/weekend factor variable.\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) |&gt;\n  \n  step_rm(date_dow) |&gt; # Remove intermediate day of week variable.\n  step_dummy(all_nominal_predictors()) |&gt; # Dummy variables for cat vars.\n  step_normalize(all_numeric_predictors()) |&gt; # Standardize num vars.\n  step_zv(all_predictors()) # For zero-variance predictor that has no information within the column.\n\n# Check summary\nsummary(bike_recipe_1)\n\n# A tibble: 12 × 4\n   variable                  type      role      source  \n   &lt;chr&gt;                     &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date                      &lt;chr [1]&gt; ID        original\n 2 seasons                   &lt;chr [3]&gt; predictor original\n 3 holiday                   &lt;chr [3]&gt; predictor original\n 4 avg_temp_c                &lt;chr [2]&gt; predictor original\n 5 avg_humidity_pct          &lt;chr [2]&gt; predictor original\n 6 avg_windspeed_m_s         &lt;chr [2]&gt; predictor original\n 7 avg_visibility_10m        &lt;chr [2]&gt; predictor original\n 8 avg_dew_point_temp_c      &lt;chr [2]&gt; predictor original\n 9 avg_solar_radiation_mj_m2 &lt;chr [2]&gt; predictor original\n10 total_rainfall_mm         &lt;chr [2]&gt; predictor original\n11 total_snowfall_cm         &lt;chr [2]&gt; predictor original\n12 total_bike_count          &lt;chr [2]&gt; outcome   original\n\n\nFor the 2nd recipe, we will repeat the steps above, as in recipe 1, but now we will add in interactions between seasons and holiday, seasons and temp, temp and rainfall.\n\nbike_recipe_2 &lt;- recipe(total_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt; # Give 'date' an ID\n  step_date(date, features = \"dow\", label = TRUE) |&gt; # Pull out week days\n  \n  # Create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) |&gt;\n  \n  step_rm(date_dow) |&gt; # Remove intermediate variable\n  \n# Interactions\n  step_interact( ~ starts_with(\"seasons_\"):starts_with(\"holiday_\")) |&gt; # seasons x holiday\n  step_interact( ~ starts_with(\"seasons_\"):starts_with(\"avg_temp_c\")) |&gt; # seasons x temp\n  step_interact( ~ starts_with(\"avg_temp_c\"):starts_with(\"total_rainfall_mm\")) |&gt; # temp x rainfall\n  \n  step_dummy(all_nominal_predictors()) |&gt; # Dummy variables\n  step_normalize(all_numeric_predictors()) |&gt; # Standardize\n  step_zv(all_predictors())\n\nsummary(bike_recipe_2)\n\n# A tibble: 12 × 4\n   variable                  type      role      source  \n   &lt;chr&gt;                     &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date                      &lt;chr [1]&gt; ID        original\n 2 seasons                   &lt;chr [3]&gt; predictor original\n 3 holiday                   &lt;chr [3]&gt; predictor original\n 4 avg_temp_c                &lt;chr [2]&gt; predictor original\n 5 avg_humidity_pct          &lt;chr [2]&gt; predictor original\n 6 avg_windspeed_m_s         &lt;chr [2]&gt; predictor original\n 7 avg_visibility_10m        &lt;chr [2]&gt; predictor original\n 8 avg_dew_point_temp_c      &lt;chr [2]&gt; predictor original\n 9 avg_solar_radiation_mj_m2 &lt;chr [2]&gt; predictor original\n10 total_rainfall_mm         &lt;chr [2]&gt; predictor original\n11 total_snowfall_cm         &lt;chr [2]&gt; predictor original\n12 total_bike_count          &lt;chr [2]&gt; outcome   original\n\n\nFor the 3rd and final recipe, we will repeat the steps above, as in recipe 2, but now we will add in quadratic terms for each numeric predictor.\n\nbike_recipe_3 &lt;- recipe(total_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt; # Give 'date' an ID\n  step_date(date, features = \"dow\", label = TRUE) |&gt; # Pull out week days\n  \n  # Create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) |&gt;\n  \n  step_rm(date_dow) |&gt; # Remove intermediate variable\n  \n  step_poly(all_numeric_predictors(), degree = 2) |&gt; # ADD IN QUADRATIC TERMS\n  \n# Interactions\n  step_interact( ~ starts_with(\"seasons_\"):starts_with(\"holiday_\")) |&gt; # seasons x holiday\n  step_interact( ~ starts_with(\"seasons_\"):starts_with(\"avg_temp_c\")) |&gt; # seasons x temp\n  step_interact( ~ starts_with(\"avg_temp_c\"):starts_with(\"total_rainfall_mm\")) |&gt; # temp x rainfall\n  \n  step_dummy(all_nominal_predictors()) |&gt; # Dummy variables\n  step_normalize(all_numeric_predictors()) |&gt; # Standardize\n  step_zv(all_predictors())\n\nsummary(bike_recipe_3)\n\n# A tibble: 12 × 4\n   variable                  type      role      source  \n   &lt;chr&gt;                     &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date                      &lt;chr [1]&gt; ID        original\n 2 seasons                   &lt;chr [3]&gt; predictor original\n 3 holiday                   &lt;chr [3]&gt; predictor original\n 4 avg_temp_c                &lt;chr [2]&gt; predictor original\n 5 avg_humidity_pct          &lt;chr [2]&gt; predictor original\n 6 avg_windspeed_m_s         &lt;chr [2]&gt; predictor original\n 7 avg_visibility_10m        &lt;chr [2]&gt; predictor original\n 8 avg_dew_point_temp_c      &lt;chr [2]&gt; predictor original\n 9 avg_solar_radiation_mj_m2 &lt;chr [2]&gt; predictor original\n10 total_rainfall_mm         &lt;chr [2]&gt; predictor original\n11 total_snowfall_cm         &lt;chr [2]&gt; predictor original\n12 total_bike_count          &lt;chr [2]&gt; outcome   original\n\n\nFinally, we will set up our linear model fit to use the “lm” engine. We will fit the models using 10 fold CV, then consider the training set CV error to choose a best model.\n\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(broom)\n\nHere, we will start by building a model specification. As stated earlier, we will be using a linear model on our bike data.\n\nlm_mod &lt;- \n  linear_reg() |&gt; \n  set_engine(\"lm\")\n\nThen, we can create some model workflows, which pair models and recipes together. We will need to do this for all three recipes.\n\nbike_wf1 &lt;- \n  workflow() |&gt;\n  add_model(lm_mod) |&gt;\n  add_recipe(bike_recipe_1)\n\nbike_wf2 &lt;- \n  workflow() |&gt;\n  add_model(lm_mod) |&gt;\n  add_recipe(bike_recipe_2)\n\nbike_wf3 &lt;- \n  workflow() |&gt;\n  add_model(lm_mod) |&gt;\n  add_recipe(bike_recipe_3)\n\nNext, we will fit the models using 10 fold CV.\n\nset.seed(75)\n\ncv_wf1 &lt;- bike_wf1 |&gt;\n  fit_resamples(bike_folds)\n\ncv_wf2 &lt;- bike_wf2 |&gt;\n  fit_resamples(bike_folds)\n\ncv_wf3 &lt;- bike_wf3 |&gt;\n  fit_resamples(bike_folds)\n\nNow, we can look at the training set CV error to choose our best model.\n\ncollect_metrics(cv_wf1)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   3931.       10 200.     pre0_mod0_post0\n2 rsq     standard      0.840    10   0.0158 pre0_mod0_post0\n\ncollect_metrics(cv_wf2)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   3947.       10 197.     pre0_mod0_post0\n2 rsq     standard      0.839    10   0.0152 pre0_mod0_post0\n\ncollect_metrics(cv_wf3) # Lowest RMSE\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   3868.       10 247.     pre0_mod0_post0\n2 rsq     standard      0.844    10   0.0189 pre0_mod0_post0\n\n\nSince our third model seems to have the lowest RMSE, we will fit this model to the entire training data set. Then, we will compute the RMSE metric on the test set.\n\nbest_fit &lt;- bike_wf3 |&gt;\n  last_fit(bike_split)\n\nbest_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard    4285.    pre0_mod0_post0\n2 rsq     standard       0.819 pre0_mod0_post0\n\n\nTo end, we will obtain the final model (fit on the entire training set) coefficient table.\n\nfinal_model_coeffs &lt;- best_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\nfinal_model_coeffs\n\n# A tibble: 26 × 5\n   term                        estimate std.error statistic   p.value\n   &lt;chr&gt;                          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)                  17545.       223.   78.7    7.25e-172\n 2 avg_temp_c_poly_1            -7804.      5228.   -1.49   1.37e-  1\n 3 avg_temp_c_poly_2            -2595.       965.   -2.69   7.67e-  3\n 4 avg_humidity_pct_poly_1      -4358.      1849.   -2.36   1.92e-  2\n 5 avg_humidity_pct_poly_2         41.6      478.    0.0871 9.31e-  1\n 6 avg_windspeed_m_s_poly_1      -558.       261.   -2.14   3.34e-  2\n 7 avg_windspeed_m_s_poly_2       221.       241.    0.916  3.61e-  1\n 8 avg_visibility_10m_poly_1      590.       314.    1.88   6.13e-  2\n 9 avg_visibility_10m_poly_2     -144.       240.   -0.597  5.51e-  1\n10 avg_dew_point_temp_c_poly_1  14313.      6145.    2.33   2.07e-  2\n# ℹ 16 more rows"
  }
]